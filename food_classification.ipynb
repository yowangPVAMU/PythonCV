{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 4668475,
          "sourceType": "datasetVersion",
          "datasetId": 2708274
        }
      ],
      "dockerImageVersionId": 30301,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"Food-101-Practice-data/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the data directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('Food-101-Practice-data/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:56.449509Z",
          "iopub.execute_input": "2022-12-08T05:42:56.450019Z",
          "iopub.status.idle": "2022-12-08T05:42:56.640429Z",
          "shell.execute_reply.started": "2022-12-08T05:42:56.449936Z",
          "shell.execute_reply": "2022-12-08T05:42:56.639506Z"
        },
        "trusted": true,
        "id": "pg4h3sR9HbQe"
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "torch.__version__"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:56.64221Z",
          "iopub.execute_input": "2022-12-08T05:42:56.642777Z",
          "iopub.status.idle": "2022-12-08T05:42:58.721932Z",
          "shell.execute_reply.started": "2022-12-08T05:42:56.642741Z",
          "shell.execute_reply": "2022-12-08T05:42:58.720809Z"
        },
        "trusted": true,
        "id": "oMAETCpQHbQf",
        "outputId": "c473a2f3-d816-4673-8912-9e3a98901835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:58.726149Z",
          "iopub.execute_input": "2022-12-08T05:42:58.727427Z",
          "iopub.status.idle": "2022-12-08T05:42:58.733968Z",
          "shell.execute_reply.started": "2022-12-08T05:42:58.727382Z",
          "shell.execute_reply": "2022-12-08T05:42:58.73309Z"
        },
        "trusted": true,
        "id": "ZUaq0fxyHbQf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\".\")\n",
        "image_path = data_path / \"Food-101-Practice-data\"\n",
        "image_path"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:58.736088Z",
          "iopub.execute_input": "2022-12-08T05:42:58.736591Z",
          "iopub.status.idle": "2022-12-08T05:42:58.750153Z",
          "shell.execute_reply.started": "2022-12-08T05:42:58.73656Z",
          "shell.execute_reply": "2022-12-08T05:42:58.749099Z"
        },
        "trusted": true,
        "id": "Vy-WTnXfHbQf",
        "outputId": "45ce8f3c-785b-4149-ba81-801456e5fdef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('Food-101-Practice-data')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:58.753957Z",
          "iopub.execute_input": "2022-12-08T05:42:58.755163Z",
          "iopub.status.idle": "2022-12-08T05:42:58.761079Z",
          "shell.execute_reply.started": "2022-12-08T05:42:58.755112Z",
          "shell.execute_reply": "2022-12-08T05:42:58.760121Z"
        },
        "trusted": true,
        "id": "0CFp6_L4HbQg"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:58.762167Z",
          "iopub.execute_input": "2022-12-08T05:42:58.762795Z",
          "iopub.status.idle": "2022-12-08T05:42:58.77879Z",
          "shell.execute_reply.started": "2022-12-08T05:42:58.762756Z",
          "shell.execute_reply": "2022-12-08T05:42:58.777385Z"
        },
        "trusted": true,
        "id": "JuFUacyIHbQg"
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:58.780264Z",
          "iopub.execute_input": "2022-12-08T05:42:58.780713Z",
          "iopub.status.idle": "2022-12-08T05:42:58.785955Z",
          "shell.execute_reply.started": "2022-12-08T05:42:58.780675Z",
          "shell.execute_reply": "2022-12-08T05:42:58.785312Z"
        },
        "trusted": true,
        "id": "RexToUSLHbQg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "#random.seed(42) # <- try changing this and see what happens\n",
        "\n",
        "# 1. Get all image paths (* means \"any combination\")\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# 2. Get random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:58.786997Z",
          "iopub.execute_input": "2022-12-08T05:42:58.787799Z",
          "iopub.status.idle": "2022-12-08T05:42:58.908497Z",
          "shell.execute_reply.started": "2022-12-08T05:42:58.787775Z",
          "shell.execute_reply": "2022-12-08T05:42:58.907687Z"
        },
        "trusted": true,
        "id": "c7OD3JNVHbQg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image with matplotlib\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:58.909395Z",
          "iopub.execute_input": "2022-12-08T05:42:58.909691Z",
          "iopub.status.idle": "2022-12-08T05:42:59.124478Z",
          "shell.execute_reply.started": "2022-12-08T05:42:58.909664Z",
          "shell.execute_reply": "2022-12-08T05:42:59.123747Z"
        },
        "trusted": true,
        "id": "88iALUueHbQg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:59.127589Z",
          "iopub.execute_input": "2022-12-08T05:42:59.128014Z",
          "iopub.status.idle": "2022-12-08T05:42:59.432433Z",
          "shell.execute_reply.started": "2022-12-08T05:42:59.127986Z",
          "shell.execute_reply": "2022-12-08T05:42:59.431396Z"
        },
        "trusted": true,
        "id": "FAiFpZXfHbQg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Write transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:59.434901Z",
          "iopub.execute_input": "2022-12-08T05:42:59.435319Z",
          "iopub.status.idle": "2022-12-08T05:42:59.44084Z",
          "shell.execute_reply.started": "2022-12-08T05:42:59.435281Z",
          "shell.execute_reply": "2022-12-08T05:42:59.439375Z"
        },
        "trusted": true,
        "id": "05GEC5bTHbQh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.->Testing Transformation with onne image"
      ],
      "metadata": {
        "id": "BqUmA2K7HbQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path =random.sample(image_path_list, k=1)\n",
        "pil_image = Image.open(str(test_img_path[0]))\n",
        "test_transformed_image = data_transform(pil_image).permute(1, 2, 0)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(test_transformed_image)\n",
        "plt.title(f\"Transformed \\nSize: {test_transformed_image.shape}\")\n",
        "plt.axis(False)\n",
        "plt.suptitle(f\"Class: {test_img_path[0].parent.stem}\", fontsize=16)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:59.442595Z",
          "iopub.execute_input": "2022-12-08T05:42:59.443508Z",
          "iopub.status.idle": "2022-12-08T05:42:59.571878Z",
          "shell.execute_reply.started": "2022-12-08T05:42:59.443473Z",
          "shell.execute_reply": "2022-12-08T05:42:59.57077Z"
        },
        "trusted": true,
        "id": "ML5aGjL9HbQh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
        "    \"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "    Will open n image paths from image_paths, transform them\n",
        "    with transform and plot them side by side.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of target image paths.\n",
        "        transform (PyTorch Transforms): Transforms to apply to images.\n",
        "        n (int, optional): Number of images to plot. Defaults to 3.\n",
        "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    random_image_paths = random.sample(image_paths, k=n)\n",
        "    #print(f'random_image_paths : {random_image_paths}')\n",
        "    for image_path in random_image_paths:\n",
        "        #print(f'type of image_path :{type(image_path)}')\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(1, 2)\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "            ax[0].axis(\"off\")\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib\n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "            ax[1].axis(\"off\")\n",
        "\n",
        "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "plot_transformed_images(image_path_list,\n",
        "                        transform=data_transform,\n",
        "                        n=10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:42:59.57548Z",
          "iopub.execute_input": "2022-12-08T05:42:59.576205Z",
          "iopub.status.idle": "2022-12-08T05:43:01.702734Z",
          "shell.execute_reply.started": "2022-12-08T05:42:59.576171Z",
          "shell.execute_reply": "2022-12-08T05:43:01.702088Z"
        },
        "trusted": true,
        "id": "iAFyyortHbQh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Image data into torchvision.datasets.ImageFolder."
      ],
      "metadata": {
        "id": "BkYGabfuHbQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform)\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.70376Z",
          "iopub.execute_input": "2022-12-08T05:43:01.704563Z",
          "iopub.status.idle": "2022-12-08T05:43:01.718548Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.704535Z",
          "shell.execute_reply": "2022-12-08T05:43:01.716771Z"
        },
        "trusted": true,
        "id": "kiCRqi-gHbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as a list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.720459Z",
          "iopub.execute_input": "2022-12-08T05:43:01.720953Z",
          "iopub.status.idle": "2022-12-08T05:43:01.731483Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.720915Z",
          "shell.execute_reply": "2022-12-08T05:43:01.729967Z"
        },
        "trusted": true,
        "id": "mwzuUYn5HbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also get class names as a dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.733018Z",
          "iopub.execute_input": "2022-12-08T05:43:01.733527Z",
          "iopub.status.idle": "2022-12-08T05:43:01.742617Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.733494Z",
          "shell.execute_reply": "2022-12-08T05:43:01.740768Z"
        },
        "trusted": true,
        "id": "SBzmKzO5HbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.744029Z",
          "iopub.execute_input": "2022-12-08T05:43:01.744369Z",
          "iopub.status.idle": "2022-12-08T05:43:01.755356Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.744342Z",
          "shell.execute_reply": "2022-12-08T05:43:01.754215Z"
        },
        "trusted": true,
        "id": "i2NaOpXCHbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"Image tensor:\\n{img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.756661Z",
          "iopub.execute_input": "2022-12-08T05:43:01.757021Z",
          "iopub.status.idle": "2022-12-08T05:43:01.792488Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.756987Z",
          "shell.execute_reply": "2022-12-08T05:43:01.791481Z"
        },
        "trusted": true,
        "id": "jzTzyLieHbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange the order of dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes (before and after permute)\n",
        "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.79396Z",
          "iopub.execute_input": "2022-12-08T05:43:01.794336Z",
          "iopub.status.idle": "2022-12-08T05:43:01.885826Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.794299Z",
          "shell.execute_reply": "2022-12-08T05:43:01.88484Z"
        },
        "trusted": true,
        "id": "Gx9-3KcNHbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data # this is mainly pythorch data set"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.887831Z",
          "iopub.execute_input": "2022-12-08T05:43:01.888155Z",
          "iopub.status.idle": "2022-12-08T05:43:01.895876Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.888128Z",
          "shell.execute_reply": "2022-12-08T05:43:01.895063Z"
        },
        "trusted": true,
        "id": "IpCSRMM1HbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test Datasets into DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=1, # how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
        "                              shuffle=True) # shuffle the data?\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=1,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.897307Z",
          "iopub.execute_input": "2022-12-08T05:43:01.897613Z",
          "iopub.status.idle": "2022-12-08T05:43:01.908118Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.89758Z",
          "shell.execute_reply": "2022-12-08T05:43:01.907328Z"
        },
        "trusted": true,
        "id": "h17D4zreHbQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.909514Z",
          "iopub.execute_input": "2022-12-08T05:43:01.910074Z",
          "iopub.status.idle": "2022-12-08T05:43:01.987247Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.910021Z",
          "shell.execute_reply": "2022-12-08T05:43:01.986109Z"
        },
        "trusted": true,
        "id": "MXEtXuEtHbQj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Dict, List\n",
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "    \"\"\"Finds the class folder names in a target directory.\n",
        "\n",
        "    Assumes target directory is in standard image classification format.\n",
        "\n",
        "    Args:\n",
        "        directory (str): target directory to load classnames from.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
        "\n",
        "    Example:\n",
        "        find_classes(\"food_images/train\")\n",
        "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
        "    \"\"\"\n",
        "    # 1. Get the class names by scanning the target directory\n",
        "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "    # 2. Raise an error if class names not found\n",
        "    if not classes:\n",
        "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
        "\n",
        "    # 3. Crearte a dictionary of index labels (computers prefer numerical rather than string labels)\n",
        "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "    return classes, class_to_idx"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:01.988657Z",
          "iopub.execute_input": "2022-12-08T05:43:01.98903Z",
          "iopub.status.idle": "2022-12-08T05:43:01.996664Z",
          "shell.execute_reply.started": "2022-12-08T05:43:01.988989Z",
          "shell.execute_reply": "2022-12-08T05:43:01.995778Z"
        },
        "trusted": true,
        "id": "-I9L_skKHbQj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
        "            nn.Linear(in_features=hidden_units*16*16,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv_block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data.classes)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-08T05:43:35.945032Z",
          "iopub.execute_input": "2022-12-08T05:43:35.945401Z",
          "iopub.status.idle": "2022-12-08T05:43:35.966367Z",
          "shell.execute_reply.started": "2022-12-08T05:43:35.945372Z",
          "shell.execute_reply": "2022-12-08T05:43:35.965101Z"
        },
        "trusted": true,
        "id": "--9lESEKHbQj"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}